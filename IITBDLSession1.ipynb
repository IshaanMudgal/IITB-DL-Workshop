{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zjyx9S-Ccoyy"
   },
   "source": [
    "# **Matrix** **Multiplication**\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "Input - 2 matrices of compatible sizes ('m1', 'm2')\n",
    "\n",
    "Output - Sum of elements of matrix obtained by multiplying 'm1', 'm2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_2FGRgOtzmNy"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pk\n",
    "from google.colab import files\n",
    "\n",
    "\n",
    "def multiply_matrices(m1, m2):\n",
    "    if not (m1.shape == m2.shape):\n",
    "        raise Exception('Matrices are not of the same dimenstion', m1.shape, m2.shape, 'are not compatible')\n",
    "    prod = m1*m2\n",
    "    return np.sum(prod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZrOT8lU6z_F4"
   },
   "source": [
    "# **Fully Connected Layer**\n",
    "\n",
    "---\n",
    "Neurons in a fully connected layer have full connections to all activations in the previous layer. Their activations can hence be computed with a matrix multiplication followed by a bias offset. \n",
    "\n",
    "Input - Input matrix [C x W x H] , weights [(C*W*H) x M] , bias [M x 1]\n",
    "\n",
    "Output - Output of FC Layer [1 x M]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aBkuLrIazz5Y"
   },
   "outputs": [],
   "source": [
    "def fullyconnected(ip, weights, bias):\n",
    "  out = None\n",
    "  C, W, H = ip.shape\n",
    "  reshaped_input = ip.reshape((1, int(C*W*H)))\n",
    "  out = np.dot(reshaped_input, weights) + bias\n",
    "  return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zwWk-IMFiHvH"
   },
   "source": [
    "# **Activation Layers**\n",
    "\n",
    "---\n",
    "\n",
    "**ReLU (Rectified Linear Unit)**\n",
    "\n",
    "ReLU layer will apply an elementwise activation function 'max(0,x)'  i.e. thresholding at zero. This leaves the size of the volume unchanged.\n",
    "\n",
    "![RELU](https://cdn-images-1.medium.com/max/937/1*oePAhrm74RNnNEolprmTaQ.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "**Softmax Activation**\n",
    "\n",
    "The softmax function squashes the outputs of each unit to be between 0 and 1 and it also divides each output such that the total sum of the outputs is equal to 1.\n",
    "The output of the softmax function is equivalent to a categorical probability distribution, it tells you the probability that any of the classes are true.\n",
    "\n",
    "![Softmax](https://cloud.githubusercontent.com/assets/14886380/22743247/9eb7c856-ee54-11e6-98ca-a7e03120b1f8.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_5ufcgkVz0zn"
   },
   "outputs": [],
   "source": [
    "class Activation:\n",
    "    ## act_type: 0 = ReLU\n",
    "    ##           1 = Softmax\n",
    "    ##           2 = Sigmoid\n",
    "    def __init__(self, ip, act_type):\n",
    "        self.ip = ip\n",
    "        self.act_type = act_type\n",
    "    \n",
    "    def relu(self):\n",
    "        input = self.ip  \n",
    "        relu_out = np.zeros(input.shape)  \n",
    "        for map_num in range(input.shape[-1]):  \n",
    "            for r in np.arange(0,input.shape[0]):  \n",
    "                for c in np.arange(0, input.shape[1]):  \n",
    "                    relu_out[r, c, map_num] = np.max(input[r, c, map_num], 0) \n",
    "        return relu_out \n",
    "\n",
    "    def softmax(self):\n",
    "        out = np.exp(self.ip) \n",
    "        return out / np.sum(out)\n",
    "\n",
    "    def forward_pass(self):\n",
    "        if (self.act_type == 0):\n",
    "            return self.relu()\n",
    "        if (self.act_type == 1):\n",
    "            return self.softmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dIpBqxx8YA9q"
   },
   "source": [
    "# **Convolution Layer**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Convolution layer will compute the output of neurons that are connected to local regions in the input, each computing a dot product between their weights and a small region they are connected to in the input volume. \n",
    "\n",
    "\n",
    "![Convolution](https://media.giphy.com/media/i4NjAwytgIRDW/giphy.gif)\n",
    "\n",
    "# **Zero padding**\n",
    "\n",
    "---\n",
    "\n",
    "Sometimes it will be convenient to pad the input volume with zeros around the border. The size of this zero-padding is a hyperparameter. The nice feature of zero padding is that it will allow us to control the spatial size of the output volumes\n",
    "\n",
    "\n",
    "![Zero padding](data:image/png;base64,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)\n",
    "\n",
    "# **Stride**\n",
    "\n",
    "---\n",
    "\n",
    "The stride specifies the value with which we slide the filter. When the stride is 1 then we move the filters one pixel at a time. When the stride is 2 (or uncommonly 3 or more, though this is rare in practice) then the filters jump 2 pixels at a time as we slide them around. This will produce smaller output volumes spatially.\n",
    "\n",
    "**In the gif below, stride is 2**\n",
    "\n",
    "![alt text](http://deeplearning.net/software/theano/_images/numerical_padding_strides.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D0_xqL-zzr1H"
   },
   "outputs": [],
   "source": [
    "class ConvLayer():\n",
    "    def __init__(self, layer_type, ip, kernels, stride=1, padding=1):\n",
    "        self.layer_type = layer_type\n",
    "        self.ip = ip\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "        self.kernels = kernels\n",
    "        return\n",
    "    \n",
    "    def _conv_maps(self, cmap, kernel):\n",
    "        ip_size, ip_size = cmap.shape\n",
    "        kernel_size, kernel_size = kernel.shape\n",
    "        output_size = int((ip_size - kernel_size + self.padding)/self.stride)\n",
    "        #### Create a new padded input map\n",
    "        padded_size = ip_size + self.padding\n",
    "        cmap_padded = np.zeros([padded_size, padded_size])\n",
    "        for col in range(padded_size):\n",
    "            for row in range(padded_size):\n",
    "                if (row >= ip_size) or (col >= ip_size):\n",
    "                    break\n",
    "                cmap_padded[row + self.padding//2, col + self.padding//2] = cmap[row, col]\n",
    "\n",
    "        #### Compute the output map\n",
    "        output_map = np.zeros([ip_size, ip_size])\n",
    "        try:\n",
    "            for c in range(ip_size):\n",
    "                for r in range(ip_size):\n",
    "                    m1 = cmap_padded[c:c+(kernel_size - self.padding//2 + 1), r:r + (kernel_size - self.padding//2 + 1)]\n",
    "                    output_map[c][r] = multiply_matrices(m1, kernel)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        return output_map\n",
    "      \n",
    "    def _conv_3d_maps(self, cmap, kernel):\n",
    "      num_channels, ip_size, ip_size = cmap.shape\n",
    "      num_kernel_channels, kernel_size, kernel_size = kernel.shape\n",
    "      if not (num_channels == num_kernel_channels):\n",
    "        print(\"Mismatch in number of channels of kernel and input image\")\n",
    "      output_size = int((ip_size - kernel_size + self.padding)/self.stride)\n",
    "      output_size = output_size\n",
    "      #### Create a new padded input map\n",
    "      padded_size = ip_size + self.padding\n",
    "      cmap_padded = np.zeros([num_channels, padded_size, padded_size])\n",
    "      for c in range(num_channels):\n",
    "        for col in range(padded_size):\n",
    "            for row in range(padded_size):\n",
    "                if (row >= ip_size) or (col >= ip_size):\n",
    "                    break\n",
    "                cmap_padded[c, row + self.padding//2, col + self.padding//2] = cmap[c, row, col]\n",
    "\n",
    "      #### Compute the output map\n",
    "      output_size, output_size = padded_size//self.stride, padded_size//self.stride\n",
    "      output_map_3d = np.zeros([output_size, output_size])\n",
    "      stride = self.stride\n",
    "      try:\n",
    "          cmap_iter_row = self.padding//2\n",
    "          cmap_iter_col = self.padding//2\n",
    "          out_col, out_row = 0, 0\n",
    "          while (out_row < output_size):\n",
    "              while (out_col < output_size):\n",
    "                  m1 = cmap_padded[:, cmap_iter_row - kernel_size//2:cmap_iter_row + kernel_size//2 + 1, cmap_iter_col - kernel_size//2:cmap_iter_col + kernel_size//2 + 1]\n",
    "                  output_map_3d[out_row][out_col] = np.sum(multiply_matrices(m1, kernel))                  \n",
    "                  cmap_iter_col += stride\n",
    "                  out_col += 1\n",
    "              out_row += 1\n",
    "              cmap_iter_row += stride\n",
    "\n",
    "        #   for c in range(ip_size):\n",
    "        #       for r in range(ip_size):\n",
    "        #           m1 = cmap_padded[:, c:c+(kernel_size - self.padding//2 + 1), r:r + (kernel_size - self.padding//2 + 1)]\n",
    "        #           output_map_3d[c][r] = np.sum(multiply_matrices(m1, kernel))\n",
    "      except Exception as e:\n",
    "          print(e)\n",
    "          \n",
    "      return output_map_3d\n",
    "\n",
    "    def forward_pass(self):\n",
    "        this_input = self.ip\n",
    "        ip_depth, ip_size, ip_size = this_input.shape\n",
    "        num_kernels, kernel_depth, kernel_size, kernel_size = self.kernels.shape\n",
    "        outputs = []\n",
    "        for kernel_id in range(num_kernels):\n",
    "          out_map = np.zeros((ip_size, ip_size))\n",
    "          out_map = self._conv_3d_maps(this_input, self.kernels[kernel_id])\n",
    "#           for map_id, ip_map in enumerate(this_input):\n",
    "#               out_map_ = self._conv_maps(ip_map, self.kernels[kernel_id][map_id])\n",
    "#               out_map += out_map_\n",
    "          outputs.append(out_map)\n",
    "        return np.array(outputs)\n",
    "\n",
    "    def test(self):\n",
    "        cmap = np.ones([5, 10, 10])\n",
    "        print(cmap.shape)\n",
    "        self.ip = cmap\n",
    "        out = self.forward_pass()\n",
    "        print(out[0].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yfbMC608riXC"
   },
   "source": [
    "# **Pooling**\n",
    "\n",
    "Its function is to progressively reduce the spatial size of the representation to reduce the amount of parameters and computation in the network, and hence to also control overfitting. The Pooling Layer operates independently on every depth slice of the input and resizes it spatially, using the MAX operation. The most common form is a pooling layer with filters of size 2x2 applied with a stride of 2 downsamples every depth slice in the input by 2 along both width and height, discarding 75% of the activations.\n",
    "\n",
    "![alt text](https://www.cntk.ai/jup/c103d_max_pooling.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MzTPQQFaamf7"
   },
   "outputs": [],
   "source": [
    "def pooling(input, size=2, stride=2):  \n",
    "    pool_out = np.zeros((np.uint16((input.shape[0] - size + 1)/stride),  \n",
    "                            np.uint16((input.shape[1] - size + 1)/stride),  \n",
    "                            input.shape[-1]))  \n",
    "    for map_num in range(input.shape[-1]):  \n",
    "        r2 = 0  \n",
    "        for r in np.arange(0, input.shape[0] - size - 1, stride):  \n",
    "            c2 = 0  \n",
    "            for c in np.arange(0, input.shape[1] - size-1, stride):  \n",
    "                pool_out[r2, c2, map_num] = np.max(input[r:r+size, c:c+size])  \n",
    "                c2 = c2 + 1  \n",
    "            r2 = r2 +1  \n",
    "\treturn pool_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6QUKvSa9HK8q"
   },
   "source": [
    "# Load Pre Trained Model Weights\n",
    "\n",
    "Load pre trained model weights, trained on CIFAR 10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VdZAcPqXFotc"
   },
   "outputs": [],
   "source": [
    "def uploader():\n",
    "  uploaded = files.upload()\n",
    "  for fn in uploaded.keys():\n",
    "    print('user uploaded file {name} with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "06JqhahZG3Wl"
   },
   "outputs": [],
   "source": [
    "def loader(input_weights_file):\n",
    "  weights = pk.load(open(input_weights_file, 'r'))\n",
    "  return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cdEv1ohkX-Kl"
   },
   "source": [
    "# **Model Definition**\n",
    "\n",
    "\n",
    "![alt text](https://raw.githubusercontent.com/IshaanMudgal/IITB-DL-Workshop/master/Capture.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "im0RIiKvz3Dm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = np.random.random((3, 32, 32))\n",
    "end_points = {}\n",
    "NUM_CLASSES = 3\n",
    "uploader()\n",
    "filename = ''\n",
    "m_weights = loader(filename)\n",
    "\n",
    "### Load preweights for the network ###\n",
    "layer1_kernels = m_weights['conv2d_1']\n",
    "layer2_kernels = m_weights['conv2d_2']\n",
    "layer3_weights = m_weights['dense_3']\n",
    "layer4_weights = m_weights['dense_4']\n",
    "\n",
    "##### ConvLayer1 #####\n",
    "layer1_kernels = np.random.random((32, 3, 3, 3))\n",
    "layer1_stride = 1\n",
    "layer1_padding = 2\n",
    "layer1 = ConvLayer(1, inputs, layer1_kernels, layer1_stride, layer1_padding)\n",
    "layer1_out = layer1.forward_pass()\n",
    "end_points['convlayer1'] = layer1_out\n",
    "print(\"convlayer1 output ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "etCo_00GTKEb"
   },
   "outputs": [],
   "source": [
    "##### Act1 #####\n",
    "act1_inputs = layer1_out\n",
    "act1 = Activation(act1_inputs, 0)\n",
    "act1_outs = act1.forward_pass()\n",
    "end_points['act1'] = act1_outs\n",
    "\n",
    "##### ConvLayer2 #####\n",
    "layer2_inputs = act1_outs\n",
    "layer2_kernels = np.random.random((64, 32, 3, 3))\n",
    "layer2_stride = 2\n",
    "layer2_padding = 2\n",
    "layer2 = ConvLayer(2, layer2_inputs, layer2_kernels, layer2_stride, layer2_padding)\n",
    "layer2_out = layer2.forward_pass()\n",
    "end_points['convlayer2'] = layer2_out\n",
    "print(\"conv2 outputs ready\")\n",
    "\n",
    "##### Act2 #####\n",
    "act2_inputs = layer2_out\n",
    "act2 = Activation(act2_inputs, 0)\n",
    "act2_outs = act2.forward_pass()\n",
    "end_points['act2'] = act2_outs\n",
    "print(act2_outs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PZXGfxUsT2mg"
   },
   "outputs": [],
   "source": [
    "##### Dense 3 #####\n",
    "layer3_inputs = act2_outs\n",
    "layer3_weights = np.random.rand(65536, 1024)\n",
    "layer3_bias = np.random.rand(1024)\n",
    "layer3_out = fullyconnected(layer3_inputs, layer3_weights, layer3_bias)\n",
    "## Normalization\n",
    "layer3_outs = layer3_out/np.max(layer3_out)\n",
    "end_points['FC'] = layer3_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LlC-6lB5IXD9"
   },
   "outputs": [],
   "source": [
    "##### Dense 3 #####\n",
    "layer4_inputs = layer3_outs\n",
    "layer4_weights = np.random.rand(1024, NUM_CLASSES)\n",
    "layer4_bias = np.random.rand(NUM_CLASSES)\n",
    "layer4_out = fullyconnected(layer4_inputs, layer4_weights, layer4_bias)\n",
    "end_points['FC'] = layer4_out\n",
    "layer4_out = layer4_out/np.max(layer4_out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fwreyOKjIYak"
   },
   "outputs": [],
   "source": [
    "##### final Activation #####\n",
    "act3_inputs = layer3_out\n",
    "act3 = Activation(act3_inputs, 1)\n",
    "act3_outs = act3.forward_pass()\n",
    "end_points['act3'] = act3_outs\n",
    "\n",
    "print(end_points['act3'])\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Hello, Colaboratory",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
